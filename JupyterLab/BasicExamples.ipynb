{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c7da1c",
   "metadata": {},
   "source": [
    "# Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d3980",
   "metadata": {},
   "source": [
    "Although Jupyter Notebook is designed primarily for data analysts, I think there are other use cases in which it can be an effective method of distributing Python code and associated documentation in a single *.ipynb* file. There are other editors we can use to handle *.ipynb* files: JupyterLab, [Deepnote](https://deepnote.com/) and Visual Studio Code (with the right extensions) are just a few I've tried."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534445e",
   "metadata": {},
   "source": [
    "Jupyter Notebook is essentially a markdown editor with an embedded Python interpreter that executes whatever code is included in a document. All the code within a document can be run as a single Python script, but it's possible to run the contents of specific code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be489e",
   "metadata": {},
   "source": [
    "I got started by installing [the Anaconda Navigator](https://www.anaconda.com/products/individual). Anaconda appears to be a Web server that hosts a range of data analysis applications, including Jupyter Notebook and JupyterLab, a Python interpreter and a large collection of modules that a data analyst might use. It can also launch the Spyder IDE and PyQT Console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59350ea",
   "metadata": {},
   "source": [
    "To get started, run the Anaconda Navigator, and in the options select '*Jupyter Notebook*'. The application's interface is accessible in a Web browser at localhost:8888."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df433a3f",
   "metadata": {},
   "source": [
    "All the mathematical and arithmetic things are done the same way as with any Python-capable IDE, because that's essentially what's happening here. I haven't tried using specialist Python modules (e.g. networking, cryptography, etc.) with Jupyter yet, though.\n",
    "There are functions that are particularly relevant for working with data sets. To find the max and min values in a set of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f40c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "myFirstVariable = 2312\n",
    "mySecondVariable = 1339\n",
    "myThirdVariable = 9878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f50d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(myFirstVariable, mySecondVariable, myThirdVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faeff80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9878"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(myFirstVariable, mySecondVariable, myThirdVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b56ef0",
   "metadata": {},
   "source": [
    "And to find the range of a data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1220cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8539"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest = max(myFirstVariable, mySecondVariable, myThirdVariable)\n",
    "smallest = min(myFirstVariable, mySecondVariable, myThirdVariable)\n",
    "mySetRange = largest - smallest\n",
    "mySetRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104e0e3",
   "metadata": {},
   "source": [
    "However, a more efficient way of dealing with relatively small data sets might be to use arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a37a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4512.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = [2312, 1339, 9878, 4521]\n",
    "\n",
    "average = sum(dataSet)/len(dataSet)\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "530156f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312\n",
      "1339\n",
      "9878\n",
      "4521\n"
     ]
    }
   ],
   "source": [
    "for i in dataSet:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899afefe",
   "metadata": {},
   "source": [
    "If we wanted to find the median of the set, we might be better off using the median() function from the statistics module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7609585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "\n",
    "stats.median(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb3bf6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0385b78",
   "metadata": {},
   "source": [
    "## Loading JSON Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8299147",
   "metadata": {},
   "source": [
    "What about if we really wanted to work with data sets with real-world data, and use Jupyter/Python to query data sources with numerous records? One method is to read it from a JSON array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1fbe6ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FirstVariable': {'name': 'First Variable', 'value': 498},\n",
       " 'SecondVariable': {'name': 'Second Variable', 'value': 677},\n",
       " 'ThirdVariable': {'name': 'Third Variable', 'value': 121}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData = { 'FirstVariable' : {'name': 'First Variable', 'value' : 498 },\n",
    "            'SecondVariable' : {'name': 'Second Variable', 'value' : 677 }, \n",
    "            'ThirdVariable' : {'name': 'Third Variable', 'value' : 121 }}\n",
    "jsonData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738650a",
   "metadata": {},
   "source": [
    "To retrieve a specific named element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "702160d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Second Variable', 'value': 677}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData['SecondVariable']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf20477",
   "metadata": {},
   "source": [
    "We can load JSON from an external file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonFile = open(\"sample.json\",)\n",
    "\n",
    "data = json.load(jsonFile)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59f153",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa713d0f",
   "metadata": {},
   "source": [
    "## Importing Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e31182",
   "metadata": {},
   "source": [
    "Of course, Jupyter Notebook wouldn't be of much use if it could work only with a limited amount of data. Fortunately there are ways of importing and working with much larger data sets, using the *pandas* module.\n",
    "To read a spreadsheet file and display its contents in Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "data = read_excel('MySpreadsheet.xls')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bfce9",
   "metadata": {},
   "source": [
    "The table that appears is called a 'dataframe'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239beec",
   "metadata": {},
   "source": [
    "You'll probably want to work on data in a given column. The following code declares *tbColumn* as an array of values in the spreadsheet's *Value* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ba3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbColumn = data['Value']\n",
    "tbColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10ff96",
   "metadata": {},
   "source": [
    "The output should tell us that *tbColumn* is an array of int64 values. We can, of course, retrieve whatever values we want from this, in the usual way. e.g.\n",
    "```dbColumn[3]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6e4b0",
   "metadata": {},
   "source": [
    "There are a few handy things we can do with an array in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbColumn.sum()\n",
    "tbColumn.min()\n",
    "tbColumn.max()\n",
    "tbColumn.mean()\n",
    "tbColumn.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739d6af",
   "metadata": {},
   "source": [
    "We also have a table sorting function, so we can sort rows by the values in a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddecd1d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d39828",
   "metadata": {},
   "source": [
    "## CSV Data Sources and Matplotlib - A Real-World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4ff98",
   "metadata": {},
   "source": [
    "I've used using [*pandas*](https://pandas.pydata.org) to read and query [real-world data provided by Our World in Data](https://ourworldindata.org/local-covid-uk) as *.csv* files - the ones used here were downloaded on 26th November. The first data set is '*UK: Daily new confirmed COVID-19 cases per 100,000*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "64e23808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "csvdata = read_csv('covid-cases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4088d",
   "metadata": {},
   "source": [
    "As expected, there was a large number of records, and they were for each region in Britain. I wanted just the stats for Wales in 2021. It was at this point that I discovered there's a *pandas.query()* function that enables us to use SQL-like syntax for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdata = read_csv('covid-cases.csv')\n",
    "\n",
    "filteredData = csvdata.query(\"(Entity=='Wales') and (Day > '2021-01-01')\")\n",
    "filteredData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa649252",
   "metadata": {},
   "source": [
    "For some very basic data visualisation, I used *Matplotlib*, setting the two columns in my filtered data as the x and y axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a561c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = filteredData.Day\n",
    "y = filteredData.daily_cases_rate_rolling_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dc8d",
   "metadata": {},
   "source": [
    "The same could be done with the second data set, which is for '*UK: Number of COVID-19 patients in hospital*'. It's very important to be very careful when naming the variables here, to avoid accidentally reading, querying or rendering from the previous data set (Note: I didn't filter for 2021 data in this second example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a52800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "csvpatients = read_csv('covid-hospital.csv')\n",
    "\n",
    "filteredHospitalData = csvpatients.query(\"(Entity=='Wales') and (Day > '2020-01-01')\")\n",
    "\n",
    "xh = filteredHospitalData.Day\n",
    "yh = filteredHospitalData.people_in_hospital\n",
    "\n",
    "plt2.plot(xh, yh)\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5a034",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
